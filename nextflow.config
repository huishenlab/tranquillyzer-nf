/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Shared parameters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

includeConfig 'conf/params.config'

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Pipeline manifest
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

manifest {
  name            = 'AyushSemwal/tranquillyzer-nf'
  homePage        = 'https://github.com/AyushSemwal/tranquillyzer-nf'
  description     = 'Nextflow DSL2 pipeline for long-read RNA-seq data with Tranquillyzer'
  mainScript      = 'main.nf'
  version         = '0.1.0'
  nextflowVersion = '>=23.10.0'
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Helpers
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

def _s(x) { x == null ? '' : x.toString() }
def _t(x) { _s(x).trim() }

def _binds() {
  (params.container_binds ?: [])
    .collect { "--bind ${it}" }
    .join(' ')
}

/**
 * If using apptainer/singularity and the image looks like a Docker image (no .sif and no scheme),
 * prefix with docker:// so it runs consistently.
 */
def _img(String image) {
  def engine = _t(params.container_engine).toLowerCase()
  if (!image) return image
  if ((engine == 'apptainer' || engine == 'singularity') &&
      !image.contains('://') &&
      !image.endsWith('.sif')) {
    return "docker://${image}"
  }
  return image
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Environment (GPU libs for apptainer/singularity if provided)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

env {
  APPTAINERENV_LD_LIBRARY_PATH = _t(params.cuda_lib_dir)
    ? "${_t(params.cuda_lib_dir)}:${System.getenv('APPTAINERENV_LD_LIBRARY_PATH') ?: ''}"
    : null

  LD_LIBRARY_PATH = _t(params.cuda_lib_dir)
    ? "${_t(params.cuda_lib_dir)}:${System.getenv('LD_LIBRARY_PATH') ?: ''}"
    : null
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Global execution defaults
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

process {
  // Default container used by most processes (engine-aware normalization)
  container = _img(_t(params.container_trq))

  // Reasonable defaults; override via labels / withName
  errorStrategy = 'terminate'
  maxRetries    = 1

  // Make task tags helpful in trace/timeline
  tag = { "${task.process} (${task.attempt})" }
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Executor selection
    - Prefer profiles for infrastructure, but keep params.executor working too.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

process.executor = (_t(params.executor) ? _t(params.executor) : 'local')

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Container engines
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

def _engine = _t(params.container_engine).toLowerCase()
docker.enabled      = (_engine == 'docker')
singularity.enabled = (_engine == 'singularity')
apptainer.enabled   = (_engine == 'apptainer')

if (singularity.enabled) {
  singularity.autoMounts = true
  singularity.cacheDir   = params.image_dir
  singularity.runOptions = _binds()
}
if (apptainer.enabled) {
  apptainer.autoMounts = true
  apptainer.cacheDir   = params.image_dir
  apptainer.runOptions = _binds()
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Executor-level throttling (queue pressure control)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

executor {
  queueSize = params.queueSize ?: 10
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    SLURM defaults (only apply when executor == slurm)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

if (process.executor == 'slurm') {
  process.queue = params.slurm_queue ?: null
  process.time  = params.slurm_time  ?: '24h'
  process.cpus  = params.slurm_cpus  ?: 8
  process.memory = params.slurm_mem ?: null  // e.g. '32 GB'
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Process-level container behavior (no duplicated profiles)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

process {

  /*
   * Concurrency controls (per-process maxForks)
   * - keeps clusters stable and avoids flooding
   */
  withName: 'TRANQUILLYZER_PIPELINE:PREPROCESS'          { maxForks = params.preprocess_maxForks    ?: 1 }
  withName: 'TRANQUILLYZER_PIPELINE:READ_LENGTH_DIST_QC' { maxForks = params.readlengthdist_maxForks?: 1 }
  withName: 'TRANQUILLYZER_PIPELINE:ANNOTATE_READS'      { maxForks = params.annotate_maxForks      ?: 1 }
  withName: 'TRANQUILLYZER_PIPELINE:ALIGN'               { maxForks = params.align_maxForks         ?: 1 }
  withName: 'TRANQUILLYZER_PIPELINE:DEDUP'               { maxForks = params.dedup_maxForks         ?: 1 }
  withName: 'TRANQUILLYZER_PIPELINE:SPLIT_BAM'           { maxForks = params.splitbam_maxForks      ?: 1 }
  withName: 'TRANQUILLYZER_PIPELINE:FEATURECOUNTS_MTX'   { maxForks = params.featurecounts_maxForks ?: 1 }

  /*
   * FeatureCounts: always use subread image, never GPU flags
   */
  withName: 'TRANQUILLYZER_PIPELINE:FEATURECOUNTS_MTX' {
    container        = _img(_t(params.container_subread))
    containerOptions = _t(params.container_extra_opts)
    clusterOptions   = ''
  }

  /*
   * CPU-labeled processes: no GPU flags
   */
  withLabel: 'cpu' {
    containerOptions = _t(params.container_extra_opts)
  }

  /*
   * GPU-labeled processes:
   * - Apply container runtime GPU flags only when enable_gpu=true
   * - Optionally apply scheduler-level GPU requests (clusterOptions) on SLURM
   */
  withLabel: 'gpu' {
    def extra = _t(params.container_extra_opts)
    def gpuEnabled = (params.enable_gpu == true)

    def gpuPrefix = ''
    if (gpuEnabled) {
      if (docker.enabled) {
        gpuPrefix = '--gpus all'
      } else if (singularity.enabled || apptainer.enabled) {
        gpuPrefix = '--nv'
      }
    }

    containerOptions = gpuEnabled
      ? "${gpuPrefix} ${extra}".trim()
      : extra

    // SLURM GPU resource request flags (cluster-specific; e.g. "--gres=gpu:1")
    clusterOptions = (process.executor == 'slurm' && gpuEnabled && _t(params.slurm_gpu_opts))
      ? _t(params.slurm_gpu_opts)
      : ''
  }
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Profiles (industry-standard infrastructure separation)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

profiles {

  // Portable default
  standard {
    process.executor = 'local'
  }

  local {
    process.executor = 'local'
  }

  slurm {
    process.executor = 'slurm'
  }

  /*
   * AWS Batch
   */
  awsbatch {
    process.executor = 'awsbatch'
    aws.region       = params.aws_region ?: null
    process.queue    = params.aws_queue  ?: null
    workDir          = params.workDir ?: workDir
  }

  /*
   * Google Life Sciences
   */
  google {
    process.executor = 'google-lifesciences'
    google.project   = params.gcp_project ?: null
    google.location  = params.gcp_region  ?: null
    workDir          = params.workDir ?: workDir
  }

  /*
   * Azure Batch
   */
  azurebatch {
    process.executor = 'azurebatch'
    azure.batch.accountName = params.azure_account ?: null
    azure.batch.location    = params.azure_region  ?: null
    workDir                 = params.workDir ?: workDir
  }

  /*
   * Kubernetes
   */
  kubernetes {
    process.executor = 'kubernetes'
    k8s.namespace    = params.k8s_namespace ?: 'default'
  }
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Reports (always on; written to outdir/pipeline_info)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

trace {
  enabled   = true
  file      = "${params.outdir}/pipeline_info/execution_trace.tsv"
  sep       = '\t'
  fields    = 'tag,task_id,process,status,exit,submit,start,complete,realtime,%cpu,cpus,peak_rss,peak_vmem'
  overwrite = true
}

report {
  enabled   = true
  file      = "${params.outdir}/pipeline_info/execution_report.html"
  overwrite = true
}

timeline {
  enabled   = true
  file      = "${params.outdir}/pipeline_info/execution_timeline.html"
  overwrite = true
}

dag {
  enabled   = true
  file      = "${params.outdir}/pipeline_info/pipeline_dag.svg"
  overwrite = true
}
