// conf/params.config

params {

  /*
   * UX / meta
   */
  help    = false
  version = false

  /*
   * Required inputs
   */
  samplesheet = null
  reference   = null
  outdir      = './results'

  /*
   * Optional inputs
   */
  gtf = null

  /*
   * Execution selection
   * - Prefer profiles for infrastructure (-profile slurm/awsbatch/google/...)
   * - Keep this for backward-compatibility / convenience if you want to drive executor via params
   */
  executor = 'local'   // local|slurm|awsbatch|google-lifesciences|azurebatch|kubernetes

  /*
   * Container configuration
   * - engine: none|docker|apptainer|singularity
   * - For apptainer/singularity: docker:// is auto-added in nextflow.config when image has no scheme and is not a .sif
   */
  container_engine     = 'apptainer'
  container_trq        = 'varishenlab/tranquillyzer:tranquillyzer_v0.2.1_tf2.15.0'
  container_subread    = 'varishenlab/featurecounts:subread2.0.6_py3.10.12'
  image_dir            = "${baseDir}/container_images"

  /*
   * GPU toggles + optional scheduler flags
   */
  enable_gpu     = false
  slurm_gpu_opts = ''              // e.g. '--gres=gpu:1' or '--gpus=1' depending on site

  /*
   * Apptainer/Singularity GPU library support (site-specific; safe defaults here)
   */
  cuda_lib_dir = ''
  container_binds = []       // e.g. ['/scratch:/scratch', '/data:/data']
  container_extra_opts = ''        // additional container runtime options (e.g. '--containall')

  /*
   * SLURM defaults (used by slurm profile)
   */
  slurm_queue = null
  slurm_time  = '24h'
  slurm_cpus  = 8
  slurm_mem   = null               // e.g. '32 GB'

  /*
   * Cloud scaffolding (used by profiles)
   */
  workDir       = null             // e.g. 's3://bucket/work' or 'gs://bucket/work'
  aws_region    = null
  aws_queue     = null
  gcp_project   = null
  gcp_region    = null
  azure_account = null
  azure_region  = null
  k8s_namespace = 'default'

  /*
   * Throttling / concurrency
   */
  queueSize               = 10

  preprocess_maxForks     = 1
  readlengthdist_maxForks = 1
  annotate_maxForks       = 1
  align_maxForks          = 1
  dedup_maxForks          = 1
  splitbam_maxForks       = 1
  featurecounts_maxForks  = 1

  /*
   * Pipeline toggles
   */
  split_bam     = true

  // Safer default: featureCounts needs a GTF. Keep it off by default; enable when --gtf is provided.
  featurecounts = false

  /*
   * Tool options
   * Tip: keep threads here aligned with process.cpus in modules, where possible.
   */
  preprocess_opts = '--output-base-qual --threads 2'

  annotate_reads_opts = [
    '--output-fmt fastq',
    '--model-name 10x3p_sc_ont_011',
    '--model-type CRF',
    '--chunk-size 300000',
    '--bc-lv-threshold 2',
    '--threads 2'
    // GPU mem flags only matter when enable_gpu=true and the module uses label 'gpu'
    // '--gpu-mem 48'
  ].join(' ')

  align_opts = '--threads 2'

  dedup_opts = '--threads 2 --lv-threshold 2'

  split_bam_opts = [
    '--bucket-threads 2',
    '--merge-threads 2',
    '--max-open-cb-writers 64'
  ].join(' ')

  featurecounts_opts = '--threads 2 --batch-size 200 --extra "-g gene_id -t exon -s 1"'
}