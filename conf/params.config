params {

  /*
   * UX / meta
   */
  help    = false
  version = false

  /*
   * Required inputs
   */
  samplesheet = null
  reference   = null
  outdir      = './results'

  /*
   * Optional inputs
   */
  gtf = null

  /*
   * Execution selection
   * - You can still override with profiles: -profile local|slurm|awsbatch|google|azurebatch|kubernetes
   * - This param is kept for compatibility / convenience
   */
  executor = 'local'   // local|slurm|awsbatch|google-lifesciences|azurebatch|kubernetes

  /*
   * Container configuration
   * - engine: none|docker|apptainer|singularity
   * - containers can be local .sif paths OR docker images (for apptainer/singularity, docker:// is auto-added in nextflow.config)
   */
  container_engine     = 'apptainer'
  container_trq        = 'varishenlab/tranquillyzer:tranquillyzer_v0.2.1_tf2.15.0'    // example; override in site configs
  container_subread    = 'varishenlab/featurecounts:subread2.0.6_py3.10.12'
  image_dir            = "${baseDir}/container_images"

  /*
   * GPU toggles + optional scheduler flags
   */
  enable_gpu      = false
  slurm_gpu_opts  = ''              // e.g. '--gres=gpu:1' or '--gpus=1' depending on site

  /*
   * Apptainer/Singularity GPU library support (site-specific; safe defaults here)
   */
  cuda_lib_dir       = ''           // e.g. '/usr/local/cuda/lib64' (optional)
  container_binds    = []           // e.g. ['/scratch:/scratch', '/data:/data']
  container_extra_opts = ''         // additional container runtime options (e.g. '--containall')

  /*
   * SLURM defaults (only used when executor/profile is slurm)
   */
  slurm_queue = null
  slurm_time  = '24h'
  slurm_cpus  = 8
  slurm_mem   = null               // e.g. '32 GB'

  /*
   * Cloud scaffolding (used by profiles)
   */
  workDir        = null            // e.g. 's3://bucket/work' or 'gs://bucket/work'
  aws_region     = null
  aws_queue      = null
  gcp_project    = null
  gcp_region     = null
  azure_account  = null
  azure_region   = null
  k8s_namespace  = 'default'

  /*
   * Throttling / concurrency
   */
  queueSize               = 10

  preprocess_maxForks     = 1
  readlengthdist_maxForks = 1
  annotate_maxForks       = 1
  align_maxForks          = 1
  dedup_maxForks          = 1
  splitbam_maxForks       = 1
  featurecounts_maxForks  = 1

  /*
   * Pipeline toggles
   */
  split_bam      = true
  featurecounts  = true

  /*
   * Tool options
   * Tip: keep threads here aligned with process.cpus in modules, where possible.
   */
  preprocess_opts = '--output-base-qual --threads 2'

  annotate_reads_opts = [
    '--output-fmt fastq',
    '--model-name 10x3p_sc_ont_011',
    '--model-type CRF',
    '--chunk-size 300000',
    '--bc-lv-threshold 2',
    '--threads 2'
    // GPU mem flags only matter when enable_gpu=true and the module uses label 'gpu'
    // '--gpu-mem 48'
  ].join(' ')

  align_opts = '--threads 2'

  dedup_opts = '--threads 2 --lv-threshold 2'

  split_bam_opts = [
    '--bucket-threads 2',
    '--merge-threads 2',
    '--max-open-cb-writers 64'
  ].join(' ')

  featurecounts_opts = '--threads 2 --batch-size 200 --extra "-g gene_id -t exon -s 1"'
}
